<HTML>

<HEAD>
<TITLE>Jason Hutchens' Papers Page</TITLE>
<LINK REV="made" HREF="mailto:hutch@ciips.ee.uwa.edu.au">
<META NAME="description" content="Jason Hutchens' research work in the areas of Grammatical Inference, Language Acquisition, Data Compression and Natural Language Processing.">
<META NAME="keywords" content="nlp,ai,grammatical inference,compression,text compression,data compression,language modeling,natural language processing,language acquisition">
</HEAD>

<BODY BGCOLOR="#FFFFFF">

<CENTER>
<H1><BIG>P</BIG>APERS</H1>
<BIG>
Jason Hutchens<BR>
Centre for Intelligent Information Processing Systems<BR>
Department of Electrical & Electronic Engineering<BR>
The University of Western Australia
</BIG>
<P>
<TABLE><TR>
<TD ALIGN="CENTRE">
[ <A HREF="../">Contents</A> |
<A HREF="../intro/">Introduction</A> |
<A HREF="../diary/">Diary</A> |
<A HREF="../seminars/">Seminars</A> |
<A HREF="../results/">Results</A> |
<A HREF="../programs/">Programs</A> |
<A HREF="../people/">People</A> |
<A HREF="../bibliography/">Bibliography</A> |
<A HREF="../contact/">Contact</A> ]
</TD>
</TR></TABLE>
</CENTER>

<H2>Introduction</H2>

You can read an information page about my papers by clicking on the title
of the paper.  This page contains publication details, an abstract,
a compressed PostScript version of the paper, and any other related files.
All papers are stored in the central
<A HREF="http://ciips.ee.uwa.edu.au/Papers/">CIIPS Papers</A>
repository, which you may
want to have a look at.

<H3><A HREF="http://ciips.ee.uwa.edu.au/Papers/Honours_Theses/1994/03/">Natural Language Grammatical Inference</A></H3>

<I>
This project is concerned with programming a computer to make predictions
about which words are most likely to follow a small segment of English text.
At first this may seem a strange problem, but I intend to show that there
exist a wide range of applications that would benefit from such a program.
Indeed, my motivation for approaching this problem was to provide a way of
improving the accuracy of speech recognition systems.
</I>

<P>
This is my honours thesis, which was submitted in 1994 in
partial fulfillment of the Bachelor of Engineering degree in Information
Technology.  A standard <TT>bibtex</TT> reference is given below:

<XMP>
@UNPUBLISHED
{
	AUTHOR = "Jason L. Hutchens",
	TITLE = "Natural Language Grammatical Inference",
	NOTE = "Honour's thesis, University of Western Australia, December 1994.
	Available at:
	{\newline {\tt http://ciips.ee.uwa.edu.au/~hutch/research/}}"
}
</XMP>

<H3><A HREF="http://ciips.ee.uwa.edu.au/Papers/Conference_Papers/1998/01/">Finding Structure via Compression</A></H3>

<I>
A statistical language model may be used to segment a data sequence by
thresholding its instantaneous entropy.  In this paper we describe
how this process works, and we apply it to the problem of discovering
separator symbols in a text.  Our results show that language models which
bootstrap themselves with structure found in this way undergo a reduction
in perplexity.
We conclude that these techniques may be useful in the design of generic
grammatical inference systems.
</I>

<P>
This paper was submitted to the International Conference on
Computational Natural Language Learning.
A standard <TT>bibtex</TT> reference is given below:

<XMP>
@INPROCEEDINGS
{
	AUTHOR = "Jason L. Hutchens and Michael D. Alder",
	BOOKTITLE = "International Conference on Computational Natural Language Learning",
	TITLE = "Finding Structure via Compression",
	PAGES = "79--82",
	MONTH = "January",
	YEAR = "1998"
}
</XMP>

<H3><A HREF="http://ciips.ee.uwa.edu.au/Papers/Conference_Papers/1998/02/">Introducing MegaHAL</A></H3>

<I>
Conversation simulators are computer programs which give the appearance of
conversing with a user in natural language.  Alan Turing devised a simple
test in order to decide whether such programs are intelligent.
In 1991, the Cambridge Centre for Behavioural Studies held the first formal
instantiation of the Turing Test.  In this incarnation the test was known as
the Loebner contest, as Dr. Hugh Loebner pledged a $100,000 grand prize for
the first computer program to pass the test.  In this paper we give a brief
background to the contest, before describing in detail the workings of
MegaHAL, the primary author's entry to the 1998 Loebner contest.
</I>

<P>
This was an invited paper for the Human-Computer Communication Workshop.
A standard <TT>bibtex</TT> reference is given below:

<XMP>
@INPROCEEDINGS
{
	AUTHOR = "Jason L. Hutchens and Michael D. Alder",
	BOOKTITLE = "Human-Computer Communication Workshop",
	TITLE = "Introducting MegaHAL",
	PAGES = "271--274",
	MONTH = "January",
	YEAR = "1998"
}
</XMP>

<H3><A HREF="http://ciips.ee.uwa.edu.au/Papers/Conference_Papers/1997/01/">Language Acquisition and Data Compression</A></H3>

<I>
Statistical data compression requires a stochastic language model
which must rapidly adapt to new data as it is encountered. A grammatical
inference engine is introduced which satisfies this requirement;
it is able to discover structure in arbitrary data using nothing more
than the predictions of a simple trigram model. We show that compression
may be used as an alternative to perplexity for language
model evaluation, and that the information processing techniques employed
by our system may reflect what happens in the human brain.
</I>

<P>
This was an invited paper at the 1997 Australasian Natural Language
Processing Summer Workshop.  The Workshop was held at Macquarie university
in Sydney, and was organised by the Microsoft Research Institute.  A standard
<TT>bibtex</TT> reference is given below:

<XMP>
@INPROCEEDINGS
{
	AUTHOR = "Jason L. Hutchens and Michael D. Alder",
	BOOKTITLE = "1997 Australasian Natural Language Processing Summer Workshop Notes",
	TITLE = "Language Acquisition and Data Compression",
	PAGES = "39--49",
	MONTH = "February",
	YEAR = "1997"
}
</XMP>

<H3><A HREF="Unavailable.html">Grammatical Inference - A Magical Mystery Tour</A></H3>
 
<I>
In this paper I give a general overview of the relatively new field
of Grammatical Inference, starting from its application in a speech
recognition system.  I cover most of the commonly used techniques,
and discuss some of the objections raised by linguists to these techniques.
In a subsequent paper I will describe my project in detail
and will cover the more philosophical aspects of this field, such as the
human language acquisition debate.
</I>

<H3><A HREF="http://ciips.ee.uwa.edu.au/Papers/Technical_Reports/1997/05/">How to Pass the Turing Test by Cheating</A></H3>

<I>
In 1991, the Cambridge Centre for Behavioural Studies held the
first formal instantiation of the Turing Test. In this incarnation the
test was known as the Loebner contest, as Dr. Hugh Loebner pledged
a $100,000 grand prize for the first computer program to pass the test.
I have submitted two computer programs to the 1996 Loebner
contest, which is to be held on Friday April 19 in New York city.
These computer programs are nothing more than glorious hacks, but
in constructing them I have learned a great deal about how language
works.
</I>

<H3><A HREF="Unavailable.html">Text Compression and Language Modeling</A></H3>

<I>
Data compression is bound up with grammatical inference and
prediction. If we can infer a grammar for some data, we may use that
grammar to compress that data and to predict what data is likely to
occur in the future.
In this paper I describe how the popular text compression techniques
actually work.  I then compare the results achieved by the
ad-hoc dictionary methods with the modern statistical methods.
</I>

<H3><A HREF="Unavailable.html">Grammatical Inference and the Upwrite Predictor</A></H3>
 
<I>
I write this report for two reasons. Firstly, to prove to my supervisor
that I have actually done something over the last six months, and
that I have had a few ideas of my own.  Secondly, and more importantly,
I write this report to "crystallise" my ideas, as Yianni puts it.
Surprisingly enough, this actually works. In fact, while thinking about
writing this report, I discovered a truly marvelous technique for doing
upwrite prediction, which, unfortunately, this abstract is too small to
contain.
</I>

<H3><A HREF="Unavailable.html">Grammatical Inference: What I Think</A></H3>

<I>
This report is what you get when you sit at the keyboard and pour your
brain out. I have basically ad-libbed it all the way, without too much concern
for organisation. That means that this report has followed my line of thought
quite closely, so I hope that this doesn't confuse the reader too much. There
are no nasty equations or anything like that, as I don't think they're necessary
to get my thoughts and ideas across.
</I>

<H3><A HREF="Unavailable.html">Jason's Travels</A></H3>

<I>
This rather long and disorganised paper is a detailed account of what I did
on my eight week "fact finding" mission, which took me to six countries and
about a dozen research institutions. Even though my schedule was very tight,
I still managed to have a bit of a holiday too, and I thought I was justified
in this because half of the travel expenses came from my own pocket.
</I>

<H2>Modification Details</H2>

Jason Hutchens' Papers Page is maintained by
<A HREF="../contact/">Jason Hutchens</A>,
and it was last modified on
<!--#echo var="LAST_MODIFIED"-->.
You are the
<!--#exec cgi="/cgi-bin/counter-nl-ord"-->
visitor to this page.

</BODY>
</HTML>

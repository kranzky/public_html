<HTML>

<HEAD>
<TITLE>Chunking for Compression</TITLE>
<LINK REV="made" HREF="mailto:hutch@ciips.ee.uwa.edu.au">
<BASE HREF="http://ciips.ee.uwa.edu.au/~hutch/research/seminars/talk4/results/">
<META NAME="description" content="Jason Hutchens' research work in the areas of Grammatical Inference, Language Acquisition, Data Compression and Natural Language Processing.">
<META NAME="keywords" content="nlp,ai,grammatical inference,compression,text compression,data compression,language modeling,natural language processing,language acquisition">
</HEAD>

<BODY BACKGROUND="figures/background.gif">

<CENTER>
<H1><BIG>R</BIG>ESULTS AND <BIG>A</BIG>NALYSIS</H1>
</CENTER>

<BR CLEAR=ALL>
<CENTER>
<TABLE BORDER=4 CELLPADDING=16 CELLSPACING=0 WIDTH="90%">
<TR><TD ALIGN="LEFT" BGCOLOR="#FFFFFF">

<BR>
<UL><LI>
Chunking improves the performance of an order-1 model significantly.
</LI></UL>

<UL><LI>
The best result beats <I>GZip </I> hands-down, and comes close to a
standard order-3 <I>PPMC </I> model.
</LI></UL>

<UL><LI>
Chunking doesn't benefit higher-order models as much, and actually
degrades performance in the case of an order-3 model.
</LI></UL>

</TD></TR>
</TABLE>
</CENTER>

<P>
<CENTER>
<TABLE>
<TR><TD>
<A HREF="Slide1.html"><IMG SRC="figures/prev.gif" BORDER=0></A>
<A HREF="../Contents.html"><IMG SRC="figures/home.gif" BORDER=0></A>
<A HREF="Slide3.html"><IMG SRC="figures/next.gif" BORDER=0></A>
</TD></TR>
</TABLE>
</CENTER>

</BODY>
</HTML>

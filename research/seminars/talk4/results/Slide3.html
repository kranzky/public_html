<HTML>

<HEAD>
<TITLE>Chunking for Compression</TITLE>
<LINK REV="made" HREF="mailto:hutch@ciips.ee.uwa.edu.au">
<BASE HREF="http://ciips.ee.uwa.edu.au/~hutch/research/seminars/talk4/results/">
<META NAME="description" content="Jason Hutchens' research work in the areas of Grammatical Inference, Language Acquisition, Data Compression and Natural Language Processing.">
<META NAME="keywords" content="nlp,ai,grammatical inference,compression,text compression,data compression,language modeling,natural language processing,language acquisition">
</HEAD>

<BODY BACKGROUND="figures/background.gif">

<CENTER>
<H1><BIG>R</BIG>ESULTS AND <BIG>A</BIG>NALYSIS</H1>
</CENTER>

<BR CLEAR=ALL>
<CENTER>
<TABLE BORDER=4 CELLPADDING=16 CELLSPACING=0 WIDTH="90%">
<TR><TD ALIGN="LEFT" BGCOLOR="#FFFFFF">

<BR>
<UL><LI>
Adaptive compressors are <B>O(n)</B>.  As John has pointed out, this is
a good sign that they aren't parallelisable.
</LI></UL>

<UL><LI>
Even worse is the fact that we can't compress different parts of the data
in parallel, as the probability of a symbol depends of the entire history. 
</LI></UL>

<UL><LI>
My program compiled fine on the <I>Onyx</I>, across all four processors, with
the net effect that it took <B>twice as long to execute</B>!
</LI></UL>

</TD></TR>
</TABLE>
</CENTER>

<P>
<CENTER>
<TABLE>
<TR><TD>
<A HREF="Slide2.html"><IMG SRC="figures/prev.gif" BORDER=0></A>
<A HREF="../Contents.html"><IMG SRC="figures/home.gif" BORDER=0></A>
<A HREF="../conclusion/"><IMG SRC="figures/next.gif" BORDER=0></A>
</TD></TR>
</TABLE>
</CENTER>

</BODY>
</HTML>
